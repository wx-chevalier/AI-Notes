# 数据清理

数据清理(data cleaning) 的主要思想是通过填补缺失值、光滑噪声数据，平滑或删除离群点，并解决数据的不一致性来“清理“数据。如果用户认为数据时脏乱的，他们不太会相信基于这些数据的挖掘结果，即输出的结果是不可靠的。

# 缺失值的处理

由于现实世界中，获取信息和数据的过程中，会存在各类的原因导致数据丢失和空缺。针对这些缺失值的处理方法，主要是基于变量的分布特性和变量的重要性（信息量和预测能力）采用不同的方法。主要分为以下几种：

- 删除变量：若变量的缺失率较高（大于 80%），覆盖率较低，且重要性较低，可以直接将变量删除。

- 定值填充：工程中常见用-9999 进行替代

- 统计量填充：若缺失率较低（小于 95%）且重要性较低，则根据数据分布的情况进行填充。对于数据符合均匀分布，用该变量的均值填补缺失，对于数据存在倾斜分布的情况，采用中位数进行填补。

- 插值法填充：包括随机插值，多重差补法，热平台插补，拉格朗日插值，牛顿插值等

- 模型填充：使用回归、贝叶斯、随机森林、决策树等模型对缺失数据进行预测。

- 哑变量填充：若变量是离散型，且不同值较少，可转换成哑变量，例如性别 SEX 变量，存在 male,fameal,NA 三个不同的值，可将该列转换成 IS_SEX_MALE, IS_SEX_FEMALE, IS_SEX_NA。若某个变量存在十几个不同的值，可根据每个值的频数，将频数较小的值归为一类'other'，降低维度。此做法可最大化保留变量的信息。

先用 pandas.isnull.sum()检测出变量的缺失比例，考虑删除或者填充，若需要填充的变量是连续型，一般采用均值法和随机差值进行填充，若变量是离散型，通常采用中位数或哑变量进行填充。注意：若对变量进行分箱离散化，一般会将缺失值单独作为一个箱子（离散变量的一个值）

# 离群点处理

异常值是数据分布的常态，处于特定分布区域或范围之外的数据通常被定义为异常或噪声。异常分为两种：“伪异常”，由于特定的业务运营动作产生，是正常反应业务的状态，而不是数据本身的异常；“真异常”，不是由于特定的业务运营动作产生，而是数据本身分布异常，即离群点。主要有以下检测离群点的方法：

- 简单统计分析：根据箱线图、各分位点判断是否存在异常，例如 pandas 的 describe 函数可以快速发现异常值。

- 3$\sigma$ 原则：若数据存在正态分布，偏离均值的 3$\sigma$ 之外. 通常定义 $P(|x-\mu|>3\sigma)<=0.03$ 范围内的点为离群点。

- 基于绝对离差中位数（MAD）：这是一种稳健对抗离群数据的距离值方法，采用计算各观测值与平均值的距离总和的方法。放大了离群值的影响。

- 基于距离：通过定义对象之间的临近性度量，根据距离判断异常对象是否远离其他对象，缺点是计算复杂度较高，不适用于大数据集和存在不同密度区域的数据集

- 基于密度：离群点的局部密度显著低于大部分近邻点，适用于非均匀的数据集

- 基于聚类：利用聚类算法，丢弃远离其他簇的小簇。

总结来看，在数据处理阶段将离群点作为影响数据质量的异常点考虑，而不是作为通常所说的异常检测目标点，因而楼主一般采用较为简单直观的方法，结合箱线图和 MAD 的统计方法判断变量的离群点。

具体的处理手段：

- 根据异常点的数量和影响，考虑是否将该条记录删除，信息损失多

- 若对数据做了 log-scale 对数变换后消除了异常值，则此方法生效，且不损失信息

- 平均值或中位数替代异常点，简单高效，信息的损失较少

- 在训练树模型时，树模型对离群点的鲁棒性较高，无信息损失，不影响模型训练效果

# 噪声点处理

噪声是变量的随机误差和方差，是观测点和真实点之间的误差。通常的处理办法：对数据进行分箱操作，等频或等宽分箱，然后用每个箱的平均数，中位数或者边界值（不同数据分布，处理方法不同）代替箱中所有的数，起到平滑数据的作用。另外一种做法是，建立该变量和预测变量的回归模型，根据回归系数和预测变量，反解出自变量的近似值。
